This application, AI-Powered Knowledge Quiz Builder, is built on the Laravel (PHP) framework and employs a decoupled Service-Oriented Architecture to manage the AI integration. The backend follows a standard MVC pattern but introduces a distinct LLM Service Layer to handle communication with the generative model. This design decision ensures separation of concerns; the core QuizService manages business logic (e.g., prompt drating, store quiz), while the LLMService focuses solely on low-level API communication, sending prompt, response parsing, and error handling. This abstraction allows for future flexibility, enabling the model backend (e.g., switching to any model).

The key technical decision was the selection of a local Large Language Model (LLM), hosted via a platform like Ollama, as the AI tool. This was chosen primarily for cost-efficiency, data privacy, and low-latency processing, making it ideal for high-volume, real-time quiz generation without incurring API costs. The specific model (e.g., gemma7b) was selected for its strong zero-shot reasoning capabilities and adherence to instructions. A critical technical decision driven by this choice was the heavy reliance on structured prompting (JSON output requests) and a robust backend parsing/validation mechanism within the LLMService to ensure the generated questions and options conform to the application's relational database schema (Question, Option Users).